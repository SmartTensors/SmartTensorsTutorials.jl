{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Introduction\n",
    "\n",
    "**Julia** is is a new-ish programming language (under active development since 2010) with a focus on high-performance scientific computating, machine learninng (ML), and artificial inteligence (AI).\n",
    "\n",
    "<img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"200\" />\n",
    "\n",
    "**Julia** includes free and open-source compiler, standard libraries, and numerous open-source packages (modules):\n",
    "- https://julialang.org\n",
    "- https://github.com/JuliaLang\n",
    "- https://juliapackages.com\n",
    "\n",
    "**Julia** is one of a very few languages in the [Petaflop club](https://www.hpcwire.com/off-the-wire/julia-joins-petaflop-club).\n",
    "\n",
    "**Julia** is ranked the [5th Most Loved Language](https://insights.stackoverflow.com/survey/2021#technology-most-loved-dreaded-and-wanted) on StackOverflow survey (more loved than python!).\n",
    "\n",
    "**Julia** looks and feels a lot like MATLAB and Python! Only it is much, much faster.\n",
    "\n",
    "**Julia** is dynamic, expressive, extensible.\n",
    "\n",
    "**Julia** development is well supported by various funding sources and projects:\n",
    "- Julia Computing recently raised [$24M in Series A funding](https://juliacomputing.com/media/2021/07/series-a)\n",
    "- **Julia** is applied to build [novel cutting-edge climate models](https://github.com/CliMA) funded by [NSF and others](https://clima.caltech.edu).\n",
    "- **Julia** is applied in various DOE funded projects (ARPA E, GTO, FE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we need yet another programming language?\n",
    "\n",
    "Yes, we do!\n",
    "\n",
    "The two-language problem is ubiquitous.\n",
    "\n",
    "Coders have to choose between:\n",
    "- code simplicity (Python)\n",
    "- code performance (C/C++/Rust)\n",
    "\n",
    "What happens in practice?\n",
    "\n",
    "The tendency is to:\n",
    "- prototype in python\n",
    "- rewrite and deploy in C/C++\n",
    "\n",
    "**Julia** solves this two-language problem, by providing a simple, fast language with native support for linear algebra, distributed computing, ML and AI.\n",
    "\n",
    "**Julia** allows you the code only ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Julia really that fast? \n",
    "\n",
    "Yes, it is!\n",
    "\n",
    "![benchmarks.svg](images/benchmarks.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Tutorials & Support\n",
    "\n",
    "The following resources provide a more comprehensive introductions and help:\n",
    "- [Introduction to Julia](https://youtu.be/r2d5NA7RHno)\n",
    "- [Julia Computing tutorials](https://github.com/JuliaComputing/JuliaBoxTutorials)\n",
    "- [Julia discourse community](https://discourse.julialang.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Future\n",
    "\n",
    "Where is Julia going?\n",
    "\n",
    "Check out the [State of Julia](https://youtu.be/IlFVwabDh6Q) talk from JuliaCon 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia REPL\n",
    "\n",
    "**Julia** REPL (read-eval-print loop) allows us to:\n",
    "* write scripts\n",
    "* execute scripts\n",
    "* evaluate variables, experessions and functions\n",
    "* get help\n",
    "* manage Julia packages (modules) and installations\n",
    "* access OS sheell\n",
    "\n",
    "<img src=\"https://github.com/SmartTensors/SmartTensorsTutorials.jl/blob/main/images/julia_REPL.png?raw=true\" width=50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Help\n",
    "\n",
    "To get help on any module, function, variable, or just about anything else, just type in the **Julia REPL** `?` followed by what you're interested in. \n",
    "\n",
    "For example, here is the help for the exponent function (`?exp`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Machine Learning\n",
    "\n",
    "**TensorFlow** and **PyTorch** are effectively languages for machine learning (ML).\n",
    "\n",
    "**TensorFlow** and **PyTorch** are coded in a wide variety of languages to meet performance and usability requirements.\n",
    "\n",
    "**TensorFlow** and **PyTorch** not only does not solve, but further expand the multi-language problem discussed above.\n",
    "\n",
    "This begs the question, which programming language could provide native support for ML?\n",
    "\n",
    "Is there a programming language that can solve the multi-language problem of the ML community?\n",
    "\n",
    "Recently, Google determined that the only viable choices are [Swift and Julia](https://github.com/tensorflow/swift/blob/main/docs/WhySwiftForTensorFlow.md).\n",
    "\n",
    "Google tried [Swift](https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/) but eventually [gave up](https://github.com/tensorflow/swift). \n",
    "\n",
    "In the meantime, the Julia ML ecosystem is going strong:\n",
    "- **Flux.jl** is the **Julia** analog of **TensorFlow** and **PyTorch**.\n",
    "- **Flux.jl** resolves the multi-language ML problem.\n",
    "- **Flux.jl** is flexibale, allowing the development and testing of novel ML methods and algorithms.\n",
    "- **Julia** provides efficient \"differentiable programming\" (DP): automated fast derivative computation for any Julia function including complex Julia-native codes like differential equation solvers. [DP is core requirement for computationally efficient ML](https://www.facebook.com/yann.lecun/posts/10155003011462143) which [is not provided at the same level](https://en.wikipedia.org/wiki/Differentiable_programming) by **TensorFlow** and **PyTorch**.\n",
    "\n",
    "\n",
    "<img src=\"images/ml-impl-comp.png\" width=50% />\n",
    "\n",
    "Reference: [ARPA-e talk by Alan Edelman (MIT & Julia Computing), Viral Shah (Julia Computing), Juan Pablo Vielma (MIT, Google), Chris Rackauckas (MIT)](https://arpa-e.energy.gov/sites/default/files/2a%20-%20Edelman%2C%20Alan%20Presentation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Scientific Computing\n",
    "\n",
    "**Julia** provides:\n",
    "\n",
    "- native linear algebra support\n",
    "- native green threads support \n",
    "- native GPU computing support\n",
    "- native distributed computing support\n",
    "- [automatic off loading](https://github.com/SciML/AutoOffload.jl) of computing efforts"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
