{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Julia_for_Pythonistas.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Julia","language":"julia","name":"julia"},"language_info":{"file_extension":".jl","mimetype":"application/julia","name":"julia"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Julia Parallel Computing\n","\n","Julia supports:\n","* coroutines (aka green threads)\n","* multithreading (without a Global interpreter lock like CPython)\n","* multiprocessing and distributed computing."],"metadata":{"id":"jgeH4A06IIX4"}},{"cell_type":"markdown","source":["## Coroutines\n","\n","Here is coroutine version of a `fibonacci()` generator function:"],"metadata":{"id":"oVCHhzbYFUv5"}},{"cell_type":"code","execution_count":null,"source":["function fibonacci(n)\n","    Channel() do ch\n","        a, b = 1, 1\n","        for i in 1:n\n","            put!(ch, a)\n","            a, b = b, a + b\n","        end\n","    end\n","end\n","\n","for f in fibonacci(10)\n","    println(f)\n","end"],"outputs":[],"metadata":{"id":"LHQ6czbxItEw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75b0ce57-cd8b-473d-e677-cbd3ba0ece42"}},{"cell_type":"markdown","source":["`Channel() do ... end` creates a `Channel` object, and spawns an asynchronous `Task` to execute the code in the `do ... end` block.\n","\n","The task is scheduled to execute immediately, but when it calls the `put!()` function on the channel to yield a value, it blocks until another task calls the `take!()` function to grab the `put!()` value.\n","\n","`take!()` function is not impleteded explicitly in the code example, since it is executed automatically in the `for` loop, in the main task.\n","\n","To demonstrate this, we can just call the `take!()` function 10 times to get all the items from the channel:"],"metadata":{"id":"mgDS2AjiVljr"}},{"cell_type":"code","execution_count":null,"source":["ch = fibonacci(10)\n","for i in 1:10\n","    println(take!(ch))\n","end"],"outputs":[],"metadata":{"id":"-tff7DpqbK-J","colab":{"base_uri":"https://localhost:8080/"},"outputId":"119fec1b-eaf0-4755-87c3-4990b822e489"}},{"cell_type":"markdown","source":["This channel is bound to the task, therefore it is automatically closed when the task ends.\n","\n","So if we try to get one more element, we will get an exception:"],"metadata":{"id":"pUZjr1wHdc5y"}},{"cell_type":"code","execution_count":null,"source":["try\n","    take!(ch)\n","catch ex\n","    ex\n","end"],"outputs":[],"metadata":{"id":"9eJjrbrHdU33","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9377e0f0-0b27-440b-da35-f589287604cf"}},{"cell_type":"markdown","source":["Here is a more explicit version of the `fibonacci()` function:"],"metadata":{"id":"VLvvfxZznXps"}},{"cell_type":"code","execution_count":null,"source":["function fibonacci(n)\n","  function generator_func(ch, n)\n","    a, b = 1, 1\n","    for i in 1:n\n","        put!(ch, a)\n","        a, b = b, a + b\n","    end\n","  end\n","  ch = Channel()\n","  task = @task generator_func(ch, n) # creates a task without starting it\n","  bind(ch, task) # the channel will be closed when the task ends\n","  schedule(task) # start running the task asynchronously\n","  ch\n","end"],"outputs":[],"metadata":{"id":"FSP1vZjheZDJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89871a44-529d-4003-8ba2-991e6d69b5f5"}},{"cell_type":"markdown","source":["And here is a more explicit version of the `for` loop:"],"metadata":{"id":"-KnzQbUGonIJ"}},{"cell_type":"code","execution_count":null,"source":["ch = fibonacci(10)\n","while isopen(ch)\n","  value = take!(ch)\n","  println(value)\n","end"],"outputs":[],"metadata":{"id":"ir3FUJAEoD5j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5fafafb3-88bb-4d5d-eafa-7fe7c524cd49"}},{"cell_type":"markdown","source":["Note that asynchronous tasks (also called \"coroutines\" or \"green threads\") are not actually run in parallel: they cooperate to alternate execution.\n","\n","Some functions, such as `put!()`, `take!()`, and many I/O functions, interrupt the current task's execution, at which point it lets Julia's scheduler decide which task should resume its execution."],"metadata":{"id":"YTwMO7gxpCSa"}},{"cell_type":"markdown","source":["## Multithreading\n","\n","Julia also supports multithreading.\n","\n","You need to specify the number of available threads upon startup, by setting the `JULIA_NUM_THREADS` environment variable (or setting the `-t` argument)."],"metadata":{"id":"N9dzuKC2qFRL"}},{"cell_type":"code","execution_count":null,"source":["if haskey(ENV, \"JULIA_NUM_THREADS\")\n","\t@info \"Number of threads:\", ENV[\"JULIA_NUM_THREADS\"]\n","else\n","\t@warn \"No treads; restart julia as `julia -t 8`\"\n","end"],"outputs":[],"metadata":{"id":"mBYUWpQpDBzS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"64cfefc5-4748-4236-f5c6-48ad06df9367"}},{"cell_type":"markdown","source":["The actual number of threads started by Julia may be lower than that, as it is limited to the number of available cores on the machine (thanks to hyperthreading, each physical core may run two threads).\n","\n","Here is the number of threads that were actually started:"],"metadata":{"id":"8AK8aRLqEhJt"}},{"cell_type":"code","execution_count":null,"source":["Base.Threads.nthreads()"],"outputs":[],"metadata":{"id":"KjEv4FOwEQhl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e37a6337-4db3-4f9b-c668-90396bb5cef3"}},{"cell_type":"markdown","source":["Now let us run 10 tasks across these threads:"],"metadata":{"id":"tc3bXp57DINZ"}},{"cell_type":"code","execution_count":null,"source":["@Base.Threads.threads for i in 1:10\n","    println(\"thread #\", Base.Threads.threadid(), \" is starting task #$i\")\n","    sleep(rand()) # pretend we're actually working\n","    println(\"thread #\", Base.Threads.threadid(), \" is finished\")\n","end"],"outputs":[],"metadata":{"id":"ic1ecJ-1qatN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f13497d-65fc-4b84-a565-d2d908b63610"}},{"cell_type":"markdown","source":["Here is a multithreaded version of the `estimate_pi()` function.\n","\n","Each thread computes part of the sum, and the parts are added at the end:"],"metadata":{"id":"SHpLG3h7LVMm"}},{"cell_type":"code","execution_count":null,"source":["import BenchmarkTools\n","\n","function parallel_estimate_pi(n)\n","  s = zeros(Threads.nthreads())\n","  nt = n รท Threads.nthreads()\n","  @Threads.threads for t in 1:Threads.nthreads()\n","      for i in (1:nt) .+ nt*(t - 1)\n","        @inbounds s[t] += (isodd(i) ? -1 : 1) / (2i + 1)\n","      end\n","  end\n","  return 4.0 * (1.0 + sum(s))\n","end\n","\n","@BenchmarkTools.btime parallel_estimate_pi(100_000_000)"],"outputs":[],"metadata":{"id":"mDHzyNqdJswG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a30b74b-1503-4802-b41c-453ea2a82c0a"}},{"cell_type":"markdown","source":["The `@inbounds` macro is an optimization: it tells the Julia compiler not to add any bounds check when accessing the array.\n","\n","It is safe in this case since the `s` array has one element per thread, and `t` varies from `1` to `Threads.nthreads()`, so there is no risk for `s[t]` to be out of bounds."],"metadata":{"id":"3Ql0KLRNSqNg"}},{"cell_type":"markdown","source":["Let's compare this with the single-threaded implementation:"],"metadata":{"id":"tVftN7gXQCOh"}},{"cell_type":"code","execution_count":null,"source":["function estimate_pi(n)\n","    s = 1.0\n","    for i in 1:n\n","        s += (isodd(i) ? -1 : 1) / (2i + 1)\n","    end\n","    return 4s\n","end\n","\n","@BenchmarkTools.btime estimate_pi(100_000_000)"],"outputs":[],"metadata":{"id":"F2Yfz67kK2xX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dd4bb6e-dad6-4dee-9c6e-f517aaa0a191"}},{"cell_type":"markdown","source":["Julia has a `mapreduce()` function which makes it easy to implement functions like `parallel_estimate_pi()`:"],"metadata":{"id":"nOUeRI6DRbmo"}},{"cell_type":"code","execution_count":null,"source":["function parallel_estimate_pi2(n)\n","    4.0 * mapreduce(i -> (isodd(i) ? -1 : 1) / (2i + 1), +, 0:n)\n","end\n","\n","@BenchmarkTools.btime parallel_estimate_pi2(100_000_000)"],"outputs":[],"metadata":{"id":"c04i5fsvO5m5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbf34ba3-5970-42ce-a361-0b57e1023e6a"}},{"cell_type":"markdown","source":["The `mapreduce()` function is well optimized, so it's about twice faster than `parallel_estimate_pi()`."],"metadata":{"id":"1Lwb_H7vTeCg"}},{"cell_type":"markdown","source":["You can also spawn a task using `Threads.@spawn`. It will get executed on any one of the running threads (it will not start a new thread):"],"metadata":{"id":"g0PXPosbamtW"}},{"cell_type":"code","execution_count":null,"source":["task = Threads.@spawn begin\n","    println(\"Thread starting\")\n","    sleep(1)\n","    println(\"Thread stopping\")\n","    return 42\n","end\n","\n","println(\"Hello!\")\n","\n","println(\"The result is: \", fetch(task))"],"outputs":[],"metadata":{"id":"w2YYrw3IYX4v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"623446f1-682e-4826-eb86-93bac386e3db"}},{"cell_type":"markdown","source":["The `fetch()` function waits for the thread to finish, and fetches the result. You can also just call `wait()` if you don't need the result."],"metadata":{"id":"pbv40Ib7bF7v"}},{"cell_type":"markdown","source":["You can also use channels to synchronize and communicate across tasks, even if they are running across separate threads:"],"metadata":{"id":"OsK9bt-Hb2IS"}},{"cell_type":"code","execution_count":null,"source":["ch = Channel()\n","task1 = Threads.@spawn begin\n","    for i in 1:5\n","        sleep(rand())\n","        put!(ch, i^2)\n","    end\n","    println(\"Finished sending!\")\n","    close(ch)\n","end\n","\n","task2 = Threads.@spawn begin\n","    foreach(v->println(\"Received $v\"), ch)\n","    println(\"Finished receiving!\")\n","end\n","\n","wait(task2)"],"outputs":[],"metadata":{"id":"sgdNzgkaceEz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3b2a2db-7cab-4004-b638-fee6ca6439c7"}},{"cell_type":"markdown","source":["## Multiprocessing & Distributed Programming\n","\n","Julia can spawn multiple Julia processes upon startup if you specify the number of processes via the `-p` argument.\n","\n","You can also spawn extra processes from Julia itself:"],"metadata":{"id":"0JfyJjTXX1AM"}},{"cell_type":"code","execution_count":null,"source":["import Distributed\n","Distributed.addprocs(4)\n","Distributed.workers() # array of worker process ids"],"outputs":[],"metadata":{"id":"JtqG4qIhX5Sw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"125f8f22-b8d0-41c7-dc4d-d681cc3f8035"}},{"cell_type":"markdown","source":["The main process has id 1:"],"metadata":{"id":"WD9hcmhGfraw"}},{"cell_type":"code","execution_count":null,"source":["Distributed.myid()"],"outputs":[],"metadata":{"id":"TlsjSMFZe3Ae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c4e1486-d667-43e0-fda8-7731f7be539e"}},{"cell_type":"markdown","source":["The `@Distributed.everywhere` macro lets you run any code on all workers:"],"metadata":{"id":"lAS3Q8ohfvwg"}},{"cell_type":"code","execution_count":null,"source":["@Distributed.everywhere println(\"Hi! I'm worker $(Distributed.myid())\")"],"outputs":[],"metadata":{"id":"lmhHLhtbenY5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad507bb1-e78e-462d-c674-a54409674444"}},{"cell_type":"markdown","source":["You can also execute code on a particular worker by using `@Distributed.spawnat <worker id> <statement>`:"],"metadata":{"id":"cyQQ0Td2hAuQ"}},{"cell_type":"code","execution_count":null,"source":["@Distributed.spawnat 3 println(\"Hi! I'm worker $(Distributed.myid())\")"],"outputs":[],"metadata":{"id":"Mmc1-zfBgsur","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de3f138f-ef52-41de-a45b-31a2fb09f2f6"}},{"cell_type":"markdown","source":["If you specify `:any` instead of a worker id, Julia chooses the worker for you:"],"metadata":{"id":"nZaV4ptbk4sB"}},{"cell_type":"code","execution_count":null,"source":["@Distributed.spawnat :any println(\"Hi! I'm worker $(Distributed.myid())\")"],"outputs":[],"metadata":{"id":"i6C7ydoBkyln","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab888bb6-6d5c-49c4-b3e7-f8b5353dd5c2"}},{"cell_type":"markdown","source":["Both `@Distributed.everywhere` and `@Distributed.spawnat` return immediately.\n","\n","The output of `@Distributed.spawnat` is a `Future` object.\n","\n","You can call `fetch()` on this object to wait for the result:"],"metadata":{"id":"fZMDIATZg9Ug"}},{"cell_type":"code","execution_count":null,"source":["result = @Distributed.spawnat 3 1+2+3+4\n","fetch(result)"],"outputs":[],"metadata":{"id":"Ml5TBZLQf2oY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c9b842b-e700-472c-f375-c67fb85ec3a6"}},{"cell_type":"markdown","source":["If you import some package in the main process, it is <u>not</u> automatically imported in the workers.\n","\n","For example, the following code fails because the worker does not know what `pyimport` is:"],"metadata":{"id":"f8rR6jBdhuvT"}},{"cell_type":"code","execution_count":null,"source":["using PyCall\n","\n","result = @Distributed.spawnat 4 (np = pyimport(\"numpy\"); np.log(10))\n","\n","try\n","    fetch(result)\n","catch ex\n","    ex\n","end"],"outputs":[],"metadata":{"id":"s89GQtv5iNfP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80df03a6-d4de-4636-bcc1-1cac598213c3"}},{"cell_type":"markdown","source":["You must use `@Distributed.everywhere` or `@Distributed.spawnat` to be able to use `using` of packages you need in each worker:"],"metadata":{"id":"N-wFnpu7inDg"}},{"cell_type":"code","execution_count":null,"source":["@Distributed.everywhere using PyCall\n","\n","result = @Distributed.spawnat 4 (np = pyimport(\"numpy\"); np.log(10))\n","\n","fetch(result)"],"outputs":[],"metadata":{"id":"eseDsHvzna1R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1e1d2c8-fbbf-4703-d3d5-227c01a82873"}},{"cell_type":"markdown","source":["Or simple you can use `import` which imports packages automatically to all workers."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import PyCall\n","\n","result = @Distributed.spawnat 4 (np = PyCall.pyimport(\"numpy\"); np.log(10))\n","\n","fetch(result)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Similarly, if you define a function in the main process, it is <u>not</u> automatically available in the workers. You must define the function in every worker:"],"metadata":{"id":"Nzk3gbLOnqTx"}},{"cell_type":"code","execution_count":null,"source":["@Distributed.everywhere addtwo(n) = n + 2\n","\n","result = @Distributed.spawnat 4 addtwo(40)\n","\n","fetch(result)"],"outputs":[],"metadata":{"id":"vrvbWhDMnzdX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a33c6b28-b083-4dea-dc49-9d7c0601f1b8"}},{"cell_type":"markdown","source":["You can pass a `Future` to `@Distributed.everywhere` or `@Distributed.spawnat`, as long as you wrap it in a `fetch()` function:"],"metadata":{"id":"9skIo6pnoikr"}},{"cell_type":"code","execution_count":null,"source":["M = @Distributed.spawnat 2 rand(5)\n","\n","result = @Distributed.spawnat 3 fetch(M) .* 10.0\n","\n","fetch(result)"],"outputs":[],"metadata":{"id":"IjovCqk7n_cu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa0808a2-aad6-4ff5-f152-8421c29eeded"}},{"cell_type":"markdown","source":["In this example, worker 2 creates a random array, then worker 3 fetches this array and multiplies each element by 10, then the main process fetches the result and displays it."],"metadata":{"id":"H4YeovYto60s"}}]}