{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726684a7",
   "metadata": {},
   "source": [
    "Notebook for artificial neural network on a geothermal dataset of Utah\n",
    "=\n",
    "More examples can be found here [MLmodels](https://github.com/FluxML/model-zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2457f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1342\n",
      "WARNING: using CUDA.uuid in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Flux: DataLoader\n",
    "using Base: @kwdef\n",
    "using CUDA\n",
    "import DelimitedFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329efba0",
   "metadata": {},
   "source": [
    "## Data loader\n",
    "For every ml model, we need data\n",
    "\n",
    "We can either generate synthetic data or load data from file\n",
    "\n",
    "Here, we will load data from file of a geothermal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633d78e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getdata (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geothermal_data = DelimitedFiles.readdlm(\"data/geothermal_data.csv\", ',', header=false);\n",
    "X               = Float32.(geothermal_data[:, 1:18]);\n",
    "y               = Int.(geothermal_data[:, end]);\n",
    "num_classes     = length(unique(y));\n",
    "\n",
    "function getdata(X, y, args, device)\n",
    "    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "\n",
    "    xtrain = X[1:Int(round(size(X, 1) * 0.6))-31, :];\n",
    "    ytrain = vec(y[1:Int(round(size(X, 1) * 0.6))-31, :]);\n",
    "    test_ind_orig = size(xtrain, 1) + 1\n",
    "    xtest  = X[test_ind_orig:end, :];\n",
    "    ytest  = vec(y[test_ind_orig:end, :]);\n",
    "    train_loader = DataLoader((data=xtrain', label=ytrain), batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader  = DataLoader((data=xtest', label=ytest), batchsize=args.batchsize)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3b1b5",
   "metadata": {},
   "source": [
    "## Build a neural network model\n",
    "Next thing is creating a neural network model\n",
    "\n",
    "Here, we will build a neural network consisting two layers each containig 32 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18264e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_model (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function build_model(; datasize=(18,50), nclasses=num_classes)\n",
    "    return Chain(Dense(prod(datasize), 32, relu),\n",
    "                  Dense(32, nclasses, softmax))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe9ae7",
   "metadata": {},
   "source": [
    "## Define loss and accuracy functions\n",
    "Next step is defining loss ($\\mathcal{L}$) and accuracy functions\n",
    "\n",
    "Loss function computes the accuracy by comparing true values versus machine learning predicted values based on a specified function.\n",
    "\n",
    "Here, we used logitcrossentropy function, which is good for classification\n",
    "\n",
    "Accuracy function computes the accuracy by comparing true values versus machine learning predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e6a3c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(data_loader, model, device)\n",
    "    acc = 0\n",
    "    ls = 0.0f0\n",
    "    num = 0\n",
    "    for (x, y) in data_loader\n",
    "        x, y = device(x), device(y)\n",
    "        ŷ = model(x)\n",
    "        ls += logitcrossentropy(ŷ, y, agg=sum)\n",
    "        acc += sum(onecold(ŷ) .== onecold(y))\n",
    "        num +=  size(x)[end]\n",
    "    end\n",
    "    return ls / num, acc / num\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa242dc",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Neural network has often several parameters\n",
    "\n",
    "Tuning those parameters help improving the model performance\n",
    "\n",
    "Values of those parameters may vary widely, so it is better to specify them\n",
    "\n",
    "Here, we are specifying three hyperparameters with just one value; however, those values can be changed during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a6ef3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct Args\n",
    "    η::Float64 = 3e-4       # learning rate\n",
    "    batchsize::Int = 50     # batch size\n",
    "    epochs::Int = 10        # number of epochs\n",
    "    use_cuda::Bool = true   # use gpu (if cuda available)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58e75a",
   "metadata": {},
   "source": [
    "## Build a training function\n",
    "We generated ML model using neural network, defined loss and accuracy functions, and also defined some hyperparameters to tune\n",
    "\n",
    "Now, we need to utilize them and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4a01030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...) # collect options in a struct for convenience\n",
    "\n",
    "    if CUDA.functional() && args.use_cuda\n",
    "        @info \"Training on CUDA GPU\"\n",
    "        CUDA.allowscalar(false)\n",
    "        device = gpu\n",
    "    else\n",
    "        @info \"Training on CPU\"\n",
    "        device = cpu\n",
    "    end\n",
    "\n",
    "    # Create test and train dataloaders\n",
    "    train_loader, test_loader = getdata(X, y, args, device)\n",
    "\n",
    "    # Construct model\n",
    "    model = build_model() |> device\n",
    "    ps = Flux.params(model) # model's trainable parameters\n",
    "    \n",
    "    ## Optimizer\n",
    "    opt = ADAM(args.η)\n",
    "    \n",
    "    ## Training\n",
    "    for epoch in 1:args.epochs\n",
    "        for (x, y) in train_loader\n",
    "            x, y = device(x), device(y) # transfer data to device\n",
    "            gs = gradient(() -> logitcrossentropy(model(x), y), ps) # compute gradient\n",
    "            Flux.Optimise.update!(opt, ps, gs) # update parameters\n",
    "        end\n",
    "        \n",
    "        # Report on train and test\n",
    "        train_loss, train_acc = loss_and_accuracy(train_loader, model, device)\n",
    "        test_loss, test_acc = loss_and_accuracy(test_loader, model, device)\n",
    "        println(\"Epoch=$epoch\")\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c427379",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run training \n",
    "if abspath(PROGRAM_FILE) == @__FILE__\n",
    "    train()\n",
    "end\n",
    "# train(η=0.01) # can change hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ea78b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main In[17]:9\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"A has dimensions (32,900) but B has dimensions (18,50)\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"A has dimensions (32,900) but B has dimensions (18,50)\")",
      "",
      "Stacktrace:",
      "  [1] gemm_wrapper!(C::Matrix{Float32}, tA::Char, tB::Char, A::Matrix{Float32}, B::Matrix{Float32}, _add::LinearAlgebra.MulAddMul{true, true, Bool, Bool})",
      "    @ LinearAlgebra /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/matmul.jl:643",
      "  [2] mul!",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/matmul.jl:169 [inlined]",
      "  [3] mul!",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/matmul.jl:275 [inlined]",
      "  [4] *",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/matmul.jl:160 [inlined]",
      "  [5] rrule",
      "    @ ~/.julia/packages/ChainRules/RyXef/src/rulesets/Base/arraymath.jl:60 [inlined]",
      "  [6] rrule",
      "    @ ~/.julia/packages/ChainRulesCore/8vlYQ/src/rules.jl:134 [inlined]",
      "  [7] chain_rrule",
      "    @ ~/.julia/packages/Zygote/EPhp6/src/compiler/chainrules.jl:180 [inlined]",
      "  [8] macro expansion",
      "    @ ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:0 [inlined]",
      "  [9] _pullback(::Zygote.Context, ::typeof(*), ::Matrix{Float32}, ::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:9",
      " [10] _pullback",
      "    @ ~/.julia/packages/Flux/ZnXxS/src/layers/basic.jl:158 [inlined]",
      " [11] _pullback(ctx::Zygote.Context, f::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, args::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:0",
      " [12] _pullback",
      "    @ ~/.julia/packages/Flux/ZnXxS/src/layers/basic.jl:47 [inlined]",
      " [13] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(softmax), Matrix{Float32}, Vector{Float32}}}, ::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:0",
      " [14] _pullback",
      "    @ ~/.julia/packages/Flux/ZnXxS/src/layers/basic.jl:49 [inlined]",
      " [15] _pullback(ctx::Zygote.Context, f::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(softmax), Matrix{Float32}, Vector{Float32}}}}, args::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:0",
      " [16] _pullback",
      "    @ ./In[17]:27 [inlined]",
      " [17] _pullback(::Zygote.Context, ::var\"#19#20\"{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(softmax), Matrix{Float32}, Vector{Float32}}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface2.jl:0",
      " [18] pullback(f::Function, ps::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface.jl:352",
      " [19] gradient(f::Function, args::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/EPhp6/src/compiler/interface.jl:75",
      " [20] train(; kws::Base.Iterators.Pairs{Symbol, Float64, Tuple{Symbol}, NamedTuple{(:η,), Tuple{Float64}}})",
      "    @ Main ./In[17]:27",
      " [21] top-level scope",
      "    @ In[19]:1",
      " [22] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "train(η=0.01) # changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7704d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
