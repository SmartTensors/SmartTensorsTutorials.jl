{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fad8cc4",
   "metadata": {},
   "source": [
    "# Simple multilayer perceptron or artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42791340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Flux\n",
    "import CUDA\n",
    "import MLDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83141094",
   "metadata": {},
   "source": [
    "## Data loader\n",
    "For every ml model, we need data\n",
    "\n",
    "We can either generate synthetic data or load data from file\n",
    "\n",
    "Here, we will load data from file of MNIST image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "function getdata(args, device)\n",
    "\tENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"false\"\n",
    "\n",
    "\t# Loading Dataset\n",
    "\txtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "\txtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "\t# Reshape Data in order to flatten each image into a linear array\n",
    "\txtrain = Flux.flatten(xtrain)\n",
    "\txtest = Flux.flatten(xtest)\n",
    "\n",
    "\t# One-hot-encode the labels\n",
    "\tytrain = Flux.onehotbatch(ytrain, 0:9)\n",
    "\tytest = Flux.onehotbatch(ytest, 0:9)\n",
    "\n",
    "\t# Create DataLoaders (mini-batch iterators)\n",
    "\ttrain_loader = Flux.Data.DataLoader((xtrain, ytrain), batchsize=args.batchsize, shuffle=true)\n",
    "\ttest_loader = Flux.Data.DataLoader((xtest, ytest), batchsize=args.batchsize)\n",
    "\n",
    "\treturn train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49319229",
   "metadata": {},
   "source": [
    "## Build a neural network model\n",
    "\n",
    "Next thing is creating a neural network model.\n",
    "\n",
    "Here, we will build a neural network consisting two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(; imgsize=(28,28,1), nclasses=10)\n",
    "\treturn Flux.Chain(Flux.Dense(prod(imgsize), 32, Flux.relu), Flux.Dense(32, nclasses))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5085f4",
   "metadata": {},
   "source": [
    "## Define loss and accuracy functions\n",
    "\n",
    "Next step is defining loss ($\\mathcal{L}$) and accuracy functions.\n",
    "\n",
    "Loss function computes the accuracy by comparing true values versus machine learning predicted values based on a specified function.\n",
    "\n",
    "Here, we used logitcrossentropy function, which is good for classification.\n",
    "\n",
    "Accuracy function computes the accuracy by comparing true values versus machine learning predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_and_accuracy(data_loader, model, device)\n",
    "\tacc = 0\n",
    "\tls = 0.0f0\n",
    "\tnum = 0\n",
    "\tfor (x, y) in data_loader\n",
    "\t\tx, y = device(x), device(y)\n",
    "\t\tŷ = model(x)\n",
    "\t\tls += Flux.Losses.logitcrossentropy(ŷ, y, agg=sum)\n",
    "\t\tacc += sum(Flux.onecold(ŷ) .== Flux.onecold(y))\n",
    "\t\tnum += size(x)[end]\n",
    "\tend\n",
    "\treturn ls / num, acc / num\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0a7b2",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Neural network has often several parameters.\n",
    "\n",
    "Tuning those parameters help improving the model performance.\n",
    "\n",
    "Values of those parameters may vary widely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Base.kwdef mutable struct Args\n",
    "\tη::Float64 = 3e-4       # learning rate\n",
    "\tbatchsize::Int = 256    # batch size\n",
    "\tepochs::Int = 10        # number of epochs\n",
    "\tuse_cuda::Bool = true   # use gpu (if cuda available)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3d06e",
   "metadata": {},
   "source": [
    "## Build a training function\n",
    "\n",
    "We generated a ML model neural network, defined loss and accuracy functions, and specified some hyperparameters.\n",
    "\n",
    "Now, we need to utilize them and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(; kws...)\n",
    "\targs = Args(; kws...) # collect options in a struct for convenience\n",
    "\n",
    "\tif CUDA.functional() && args.use_cuda\n",
    "\t\t@info \"Training on CUDA GPU\"\n",
    "\t\tCUDA.allowscalar(false)\n",
    "\t\tdevice = Flux.gpu\n",
    "\telse\n",
    "\t\t@info \"Training on CPU\"\n",
    "\t\tdevice = Flux.cpu\n",
    "\tend\n",
    "\n",
    "\t# Create test and train data loaders\n",
    "\ttrain_loader, test_loader = getdata(args, device)\n",
    "\n",
    "\t# Construct model\n",
    "\tmodel = build_model() |> device\n",
    "\tps = Flux.params(model) # model's trainable parameters\n",
    "\n",
    "\t## Optimizer\n",
    "\topt = Flux.ADAM(args.η)\n",
    "\n",
    "\t## Training\n",
    "\tfor epoch in 1:args.epochs\n",
    "\t\tfor (x, y) in train_loader\n",
    "\t\t\tx, y = device(x), device(y) # transfer data to device\n",
    "\t\t\tgs = Flux.gradient(()->Flux.Losses.logitcrossentropy(model(x), y), ps) # compute gradient\n",
    "\t\t\tFlux.Optimise.update!(opt, ps, gs) # update parameters\n",
    "\t\tend\n",
    "\n",
    "\t\ttrain_loss, train_acc = loss_and_accuracy(train_loader, model, device)\n",
    "\t\ttest_loss, test_acc = loss_and_accuracy(test_loader, model, device)\n",
    "\t\tprintln(\"Epoch = $epoch\")\n",
    "\t\tprintln(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "\t\tprintln(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(; η=0.01) # changing learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
